{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "KljI4jjG-IXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/aliayman15/sa3dny_project\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlhH-v2zv_F3",
        "outputId": "6ef49c6e-8f6b-4935-a831-a9dd17644ba6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'sa3dny_project'...\n",
            "remote: Enumerating objects: 204, done.\u001b[K\n",
            "remote: Counting objects: 100% (129/129), done.\u001b[K\n",
            "remote: Compressing objects: 100% (106/106), done.\u001b[K\n",
            "remote: Total 204 (delta 31), reused 94 (delta 21), pack-reused 75\u001b[K\n",
            "Receiving objects: 100% (204/204), 44.95 MiB | 33.62 MiB/s, done.\n",
            "Resolving deltas: 100% (31/31), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/aliayman15/sa3dny_project/tree/main/Face%20match%20child%20images\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2vKecpfwK56",
        "outputId": "8d8810d9-eb3b-4df8-c4dd-45ed02e763bf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-08 20:29:25--  https://github.com/aliayman15/sa3dny_project/tree/main/Face%20match%20child%20images\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8546 (8.3K) [text/plain]\n",
            "Saving to: ‘Face match child images’\n",
            "\n",
            "\rFace match child im   0%[                    ]       0  --.-KB/s               \rFace match child im 100%[===================>]   8.35K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-03-08 20:29:25 (50.2 MB/s) - ‘Face match child images’ saved [8546/8546]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -O https://github.com/aliayman15/sa3dny_project/tree/main/Face%20match%20child%20images\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ht14VE2QwkUV",
        "outputId": "78cadbcd-50f8-4386-81f0-c8755bbebf95"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  8535  100  8535    0     0  34041      0 --:--:-- --:--:-- --:--:-- 34140\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deepface"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKyUNaDc9ySI",
        "outputId": "a8beb9a8-862b-4b45-92ea-b23bf93bf44f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deepface\n",
            "  Downloading deepface-0.0.85-py3-none-any.whl (85 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/85.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.9/85.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.10/dist-packages (from deepface) (1.5.3)\n",
            "Requirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.10/dist-packages (from deepface) (4.7.3)\n",
            "Requirement already satisfied: tqdm>=4.30.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (4.66.2)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (9.4.0)\n",
            "Requirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.10/dist-packages (from deepface) (4.8.0.76)\n",
            "Requirement already satisfied: tensorflow>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.15.0)\n",
            "Requirement already satisfied: keras>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.15.0)\n",
            "Requirement already satisfied: Flask>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.2.5)\n",
            "Collecting mtcnn>=0.1.0 (from deepface)\n",
            "  Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting retina-face>=0.0.1 (from deepface)\n",
            "  Downloading retina_face-0.0.14-py3-none-any.whl (23 kB)\n",
            "Collecting fire>=0.4.0 (from deepface)\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gunicorn>=20.1.0 (from deepface)\n",
            "  Downloading gunicorn-21.2.0-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.2/80.2 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire>=0.4.0->deepface) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire>=0.4.0->deepface) (2.4.0)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (3.0.1)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->deepface) (3.13.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->deepface) (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->deepface) (4.12.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gunicorn>=20.1.0->deepface) (23.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->deepface) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->deepface) (2023.4)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (4.10.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.62.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=1.9.0->deepface) (0.42.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask>=1.1.2->deepface) (2.1.5)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (3.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (0.7.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=3.10.1->deepface) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (2024.2.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.7.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (3.2.2)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116934 sha256=82a10ff9e1ff2fdb62ff6a043b7b9d11e7fe0783c6aa2de0655a43c406f52692\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n",
            "Successfully built fire\n",
            "Installing collected packages: gunicorn, fire, mtcnn, retina-face, deepface\n",
            "Successfully installed deepface-0.0.85 fire-0.5.0 gunicorn-21.2.0 mtcnn-0.1.1 retina-face-0.0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import deepface"
      ],
      "metadata": {
        "id": "07v9N6WB95DN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfs = DeepFace.find(img_path = \"/content/sa3dny_project/13.png\", db_path = \"/content/sa3dny_project/Face match child images\",enforce_detection=False)\n",
        "print(dfs)\n",
        "\n",
        "if len(dfs) > 0:\n",
        "    print(\"Yes, there is a matched image\")\n",
        "else:\n",
        "    print(\"No matched image found\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTcpC2meNLUj",
        "outputId": "e1cacae5-a96f-4800-b992-b3f05173c050"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24-03-08 22:43:32 - find function duration 1.161848783493042 seconds\n",
            "[                                            identity  target_x  target_y  \\\n",
            "0  /content/sa3dny_project/Face match child image...       119       207   \n",
            "1  /content/sa3dny_project/Face match child image...        51        84   \n",
            "2  /content/sa3dny_project/Face match child image...        65       280   \n",
            "\n",
            "   target_w  target_h  source_x  source_y  source_w  source_h  threshold  \\\n",
            "0       494       494       119       207       494       494       0.68   \n",
            "1       199       199       119       207       494       494       0.68   \n",
            "2       542       542       119       207       494       494       0.68   \n",
            "\n",
            "       distance  \n",
            "0 -2.220446e-16  \n",
            "1  6.655594e-01  \n",
            "2  6.753617e-01  ]\n",
            "Yes, there is a matched image\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from deepface import DeepFace\n",
        "import os\n",
        "\n",
        "class FaceRecognizer:\n",
        "    def __init__(self, database_path):\n",
        "        self.database_path = database_path\n",
        "\n",
        "    def recognize_face(self, image_path):\n",
        "        try:\n",
        "            # Load the images in the database\n",
        "            database_images = [os.path.join(self.database_path, file) for file in os.listdir(self.database_path) if file.endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "            if not database_images:\n",
        "                return \"No images found in the database\"\n",
        "\n",
        "            # Recognize faces in the image using FaceNet model\n",
        "            matched_photos = []\n",
        "            for db_photo in database_images:\n",
        "                result = DeepFace.verify(image_path, db_photo, model_name='Facenet', detector_backend='opencv', enforce_detection=False)\n",
        "                print(\"Result:\", result)  # Add this line for debugging\n",
        "                if result['verified']:\n",
        "                    matched_photos.append(os.path.basename(db_photo))\n",
        "\n",
        "            if matched_photos:\n",
        "                return matched_photos\n",
        "            else:\n",
        "                return \"No face recognized in the image\"\n",
        "\n",
        "        except Exception as e:\n",
        "            print(\"Error:\", str(e))\n",
        "            return None\n",
        "\n",
        "# Usage\n",
        "recognizer = FaceRecognizer(database_path='/content/sa3dny_project/Face match child images')\n",
        "image_path = '/content/sa3dny_project/13.png'\n",
        "result = recognizer.recognize_face(image_path)\n",
        "print(\"Matched photos:\", result)\n",
        "\n",
        "def print_matched_results(result):\n",
        "    if result:\n",
        "        print(\"Matched photo found!\")\n",
        "        print(\"Similarities:\", result)\n",
        "        print()\n",
        "    else:\n",
        "        print(\"No matched image found.\")\n",
        "\n",
        "def get_matched_image(result):\n",
        "    if result:\n",
        "        return result\n",
        "    return None\n",
        "\n",
        "# Get the matched image\n",
        "matched_image = get_matched_image(result)\n",
        "\n",
        "if matched_image:\n",
        "    print(\"Matched image:\", matched_image)\n",
        "else:\n",
        "    print(\"No matched image found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToTa2kQdPqi1",
        "outputId": "d069b646-6561-4e48-ee4b-4cc352c3703c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result: {'verified': False, 'distance': 0.8848238502129959, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 119, 'y': 207, 'w': 494, 'h': 494, 'left_eye': (141, 187), 'right_eye': (340, 200)}, 'img2': {'x': 574, 'y': 146, 'w': 285, 'h': 285, 'left_eye': (81, 121), 'right_eye': (189, 119)}}, 'time': 4.7}\n",
            "Result: {'verified': False, 'distance': 0.6829494914476482, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 119, 'y': 207, 'w': 494, 'h': 494, 'left_eye': (141, 187), 'right_eye': (340, 200)}, 'img2': {'x': 100, 'y': 175, 'w': 426, 'h': 426, 'left_eye': (124, 151), 'right_eye': (304, 153)}}, 'time': 2.84}\n",
            "Result: {'verified': False, 'distance': 1.0680533115677837, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 119, 'y': 207, 'w': 494, 'h': 494, 'left_eye': (141, 187), 'right_eye': (340, 200)}, 'img2': {'x': 137, 'y': 171, 'w': 405, 'h': 405, 'left_eye': (119, 153), 'right_eye': (127, 293)}}, 'time': 2.14}\n",
            "Result: {'verified': False, 'distance': 0.5599393963754344, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 119, 'y': 207, 'w': 494, 'h': 494, 'left_eye': (141, 187), 'right_eye': (340, 200)}, 'img2': {'x': 306, 'y': 113, 'w': 357, 'h': 357, 'left_eye': (115, 130), 'right_eye': (240, 149)}}, 'time': 1.52}\n",
            "Result: {'verified': False, 'distance': 0.8788729481435624, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 119, 'y': 207, 'w': 494, 'h': 494, 'left_eye': (141, 187), 'right_eye': (340, 200)}, 'img2': {'x': 42, 'y': 360, 'w': 439, 'h': 439, 'left_eye': (108, 173), 'right_eye': (300, 147)}}, 'time': 1.58}\n",
            "Result: {'verified': False, 'distance': 0.6629336724889723, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 119, 'y': 207, 'w': 494, 'h': 494, 'left_eye': (141, 187), 'right_eye': (340, 200)}, 'img2': {'x': 226, 'y': 245, 'w': 133, 'h': 133, 'left_eye': (44, 46), 'right_eye': (91, 58)}}, 'time': 2.0}\n",
            "Result: {'verified': False, 'distance': 1.044627481629546, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 119, 'y': 207, 'w': 494, 'h': 494, 'left_eye': (141, 187), 'right_eye': (340, 200)}, 'img2': {'x': 168, 'y': 39, 'w': 182, 'h': 182, 'left_eye': None, 'right_eye': None}}, 'time': 2.27}\n",
            "Result: {'verified': False, 'distance': 0.8039733251017237, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 119, 'y': 207, 'w': 494, 'h': 494, 'left_eye': (141, 187), 'right_eye': (340, 200)}, 'img2': {'x': 204, 'y': 93, 'w': 213, 'h': 213, 'left_eye': (66, 91), 'right_eye': (135, 71)}}, 'time': 1.49}\n",
            "Result: {'verified': False, 'distance': 0.7963511252892393, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 119, 'y': 207, 'w': 494, 'h': 494, 'left_eye': (141, 187), 'right_eye': (340, 200)}, 'img2': {'x': 90, 'y': 197, 'w': 447, 'h': 447, 'left_eye': (139, 187), 'right_eye': (296, 183)}}, 'time': 1.55}\n",
            "Result: {'verified': False, 'distance': 0.8444009725253221, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 119, 'y': 207, 'w': 494, 'h': 494, 'left_eye': (141, 187), 'right_eye': (340, 200)}, 'img2': {'x': 336, 'y': 423, 'w': 172, 'h': 172, 'left_eye': (57, 70), 'right_eye': (112, 72)}}, 'time': 2.05}\n",
            "Result: {'verified': False, 'distance': 0.5446216950774567, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 119, 'y': 207, 'w': 494, 'h': 494, 'left_eye': (141, 187), 'right_eye': (340, 200)}, 'img2': {'x': 195, 'y': 188, 'w': 264, 'h': 264, 'left_eye': (84, 105), 'right_eye': (177, 108)}}, 'time': 1.54}\n",
            "Result: {'verified': False, 'distance': 0.929453179985931, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 119, 'y': 207, 'w': 494, 'h': 494, 'left_eye': (141, 187), 'right_eye': (340, 200)}, 'img2': {'x': 49, 'y': 233, 'w': 519, 'h': 519, 'left_eye': (153, 212), 'right_eye': (362, 196)}}, 'time': 1.48}\n",
            "Result: {'verified': False, 'distance': 0.9009932167379106, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 119, 'y': 207, 'w': 494, 'h': 494, 'left_eye': (141, 187), 'right_eye': (340, 200)}, 'img2': {'x': 105, 'y': 244, 'w': 403, 'h': 403, 'left_eye': (127, 157), 'right_eye': (265, 153)}}, 'time': 1.49}\n",
            "Result: {'verified': False, 'distance': 0.8157583417172279, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 119, 'y': 207, 'w': 494, 'h': 494, 'left_eye': (141, 187), 'right_eye': (340, 200)}, 'img2': {'x': 251, 'y': 215, 'w': 270, 'h': 270, 'left_eye': (83, 100), 'right_eye': (177, 105)}}, 'time': 1.75}\n",
            "Result: {'verified': False, 'distance': 1.1072753520067466, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 119, 'y': 207, 'w': 494, 'h': 494, 'left_eye': (141, 187), 'right_eye': (340, 200)}, 'img2': {'x': 218, 'y': 184, 'w': 138, 'h': 138, 'left_eye': (44, 58), 'right_eye': (88, 48)}}, 'time': 2.06}\n",
            "Result: {'verified': False, 'distance': 0.7546454813104126, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 119, 'y': 207, 'w': 494, 'h': 494, 'left_eye': (141, 187), 'right_eye': (340, 200)}, 'img2': {'x': 171, 'y': 265, 'w': 283, 'h': 283, 'left_eye': (99, 113), 'right_eye': (181, 120)}}, 'time': 1.83}\n",
            "Result: {'verified': False, 'distance': 0.8118801979676258, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 119, 'y': 207, 'w': 494, 'h': 494, 'left_eye': (141, 187), 'right_eye': (340, 200)}, 'img2': {'x': 220, 'y': 246, 'w': 199, 'h': 199, 'left_eye': (61, 68), 'right_eye': (136, 80)}}, 'time': 1.49}\n",
            "Result: {'verified': False, 'distance': 0.7289779627518882, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 119, 'y': 207, 'w': 494, 'h': 494, 'left_eye': (141, 187), 'right_eye': (340, 200)}, 'img2': {'x': 112, 'y': 200, 'w': 461, 'h': 461, 'left_eye': (122, 184), 'right_eye': (325, 184)}}, 'time': 1.44}\n",
            "Result: {'verified': False, 'distance': 0.7714700970439649, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 119, 'y': 207, 'w': 494, 'h': 494, 'left_eye': (141, 187), 'right_eye': (340, 200)}, 'img2': {'x': 79, 'y': 140, 'w': 377, 'h': 377, 'left_eye': (116, 145), 'right_eye': (253, 140)}}, 'time': 1.46}\n",
            "Result: {'verified': False, 'distance': 1.10575046650933, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 119, 'y': 207, 'w': 494, 'h': 494, 'left_eye': (141, 187), 'right_eye': (340, 200)}, 'img2': {'x': 90, 'y': 231, 'w': 477, 'h': 477, 'left_eye': (279, 345), 'right_eye': (323, 182)}}, 'time': 1.36}\n",
            "Result: {'verified': True, 'distance': 0.0, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 119, 'y': 207, 'w': 494, 'h': 494, 'left_eye': (141, 187), 'right_eye': (340, 200)}, 'img2': {'x': 119, 'y': 207, 'w': 494, 'h': 494, 'left_eye': (141, 187), 'right_eye': (340, 200)}}, 'time': 1.42}\n",
            "Result: {'verified': False, 'distance': 0.8636468898242383, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 119, 'y': 207, 'w': 494, 'h': 494, 'left_eye': (141, 187), 'right_eye': (340, 200)}, 'img2': {'x': 180, 'y': 184, 'w': 137, 'h': 137, 'left_eye': (42, 56), 'right_eye': (88, 49)}}, 'time': 3.16}\n",
            "Result: {'verified': False, 'distance': 0.7629706900106636, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 119, 'y': 207, 'w': 494, 'h': 494, 'left_eye': (141, 187), 'right_eye': (340, 200)}, 'img2': {'x': 215, 'y': 279, 'w': 282, 'h': 282, 'left_eye': (94, 100), 'right_eye': (203, 119)}}, 'time': 2.25}\n",
            "Result: {'verified': False, 'distance': 1.052525638715375, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 119, 'y': 207, 'w': 494, 'h': 494, 'left_eye': (141, 187), 'right_eye': (340, 200)}, 'img2': {'x': 160, 'y': 227, 'w': 430, 'h': 430, 'left_eye': (128, 172), 'right_eye': (291, 166)}}, 'time': 1.41}\n",
            "Result: {'verified': False, 'distance': 0.674259097465675, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 119, 'y': 207, 'w': 494, 'h': 494, 'left_eye': (141, 187), 'right_eye': (340, 200)}, 'img2': {'x': 110, 'y': 160, 'w': 449, 'h': 449, 'left_eye': (138, 190), 'right_eye': (293, 180)}}, 'time': 1.51}\n",
            "Result: {'verified': False, 'distance': 0.5831611801271797, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 119, 'y': 207, 'w': 494, 'h': 494, 'left_eye': (141, 187), 'right_eye': (340, 200)}, 'img2': {'x': 51, 'y': 84, 'w': 199, 'h': 199, 'left_eye': (57, 77), 'right_eye': (137, 75)}}, 'time': 1.12}\n",
            "Result: {'verified': False, 'distance': 1.1438839256560347, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 119, 'y': 207, 'w': 494, 'h': 494, 'left_eye': (141, 187), 'right_eye': (340, 200)}, 'img2': {'x': 0, 'y': 0, 'w': 604, 'h': 930, 'left_eye': None, 'right_eye': None}}, 'time': 1.39}\n",
            "Result: {'verified': False, 'distance': 0.5277889970807348, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 119, 'y': 207, 'w': 494, 'h': 494, 'left_eye': (141, 187), 'right_eye': (340, 200)}, 'img2': {'x': 124, 'y': 139, 'w': 336, 'h': 336, 'left_eye': (98, 120), 'right_eye': (231, 141)}}, 'time': 1.34}\n",
            "Result: {'verified': False, 'distance': 0.8957167862177494, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 119, 'y': 207, 'w': 494, 'h': 494, 'left_eye': (141, 187), 'right_eye': (340, 200)}, 'img2': {'x': 160, 'y': 373, 'w': 355, 'h': 355, 'left_eye': (112, 140), 'right_eye': (260, 133)}}, 'time': 1.39}\n",
            "Result: {'verified': False, 'distance': 1.1308320109409506, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 119, 'y': 207, 'w': 494, 'h': 494, 'left_eye': (141, 187), 'right_eye': (340, 200)}, 'img2': {'x': 0, 'y': 0, 'w': 720, 'h': 780, 'left_eye': None, 'right_eye': None}}, 'time': 1.38}\n",
            "Result: {'verified': False, 'distance': 0.7526179967427465, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 119, 'y': 207, 'w': 494, 'h': 494, 'left_eye': (141, 187), 'right_eye': (340, 200)}, 'img2': {'x': 79, 'y': 113, 'w': 250, 'h': 250, 'left_eye': (73, 107), 'right_eye': (171, 100)}}, 'time': 1.57}\n",
            "Result: {'verified': False, 'distance': 0.8971972850552081, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 119, 'y': 207, 'w': 494, 'h': 494, 'left_eye': (141, 187), 'right_eye': (340, 200)}, 'img2': {'x': 151, 'y': 150, 'w': 443, 'h': 443, 'left_eye': (134, 179), 'right_eye': (299, 178)}}, 'time': 2.13}\n",
            "Result: {'verified': False, 'distance': 0.8376047951627112, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 119, 'y': 207, 'w': 494, 'h': 494, 'left_eye': (141, 187), 'right_eye': (340, 200)}, 'img2': {'x': 118, 'y': 248, 'w': 212, 'h': 212, 'left_eye': (69, 91), 'right_eye': (137, 76)}}, 'time': 2.61}\n",
            "Result: {'verified': False, 'distance': 0.907336248496958, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 119, 'y': 207, 'w': 494, 'h': 494, 'left_eye': (141, 187), 'right_eye': (340, 200)}, 'img2': {'x': 255, 'y': 87, 'w': 290, 'h': 290, 'left_eye': (98, 115), 'right_eye': (186, 124)}}, 'time': 1.73}\n",
            "Result: {'verified': False, 'distance': 0.7840489943903701, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 119, 'y': 207, 'w': 494, 'h': 494, 'left_eye': (141, 187), 'right_eye': (340, 200)}, 'img2': {'x': 229, 'y': 34, 'w': 351, 'h': 351, 'left_eye': (116, 128), 'right_eye': (232, 138)}}, 'time': 2.28}\n",
            "Result: {'verified': False, 'distance': 0.5611204515620457, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 119, 'y': 207, 'w': 494, 'h': 494, 'left_eye': (141, 187), 'right_eye': (340, 200)}, 'img2': {'x': 195, 'y': 164, 'w': 422, 'h': 422, 'left_eye': (127, 163), 'right_eye': (280, 166)}}, 'time': 1.43}\n",
            "Result: {'verified': False, 'distance': 0.9228628519714163, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 119, 'y': 207, 'w': 494, 'h': 494, 'left_eye': (141, 187), 'right_eye': (340, 200)}, 'img2': {'x': 263, 'y': 291, 'w': 138, 'h': 138, 'left_eye': (44, 55), 'right_eye': (91, 49)}}, 'time': 1.79}\n",
            "Result: {'verified': False, 'distance': 0.7559938707418791, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 119, 'y': 207, 'w': 494, 'h': 494, 'left_eye': (141, 187), 'right_eye': (340, 200)}, 'img2': {'x': 348, 'y': 343, 'w': 279, 'h': 279, 'left_eye': (90, 111), 'right_eye': (182, 93)}}, 'time': 2.25}\n",
            "Result: {'verified': False, 'distance': 0.6995637354546322, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 119, 'y': 207, 'w': 494, 'h': 494, 'left_eye': (141, 187), 'right_eye': (340, 200)}, 'img2': {'x': 137, 'y': 115, 'w': 408, 'h': 408, 'left_eye': (119, 186), 'right_eye': (259, 141)}}, 'time': 2.52}\n",
            "Result: {'verified': False, 'distance': 0.7249749678400338, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 119, 'y': 207, 'w': 494, 'h': 494, 'left_eye': (141, 187), 'right_eye': (340, 200)}, 'img2': {'x': 135, 'y': 143, 'w': 489, 'h': 489, 'left_eye': (145, 187), 'right_eye': (318, 182)}}, 'time': 1.5}\n",
            "Result: {'verified': False, 'distance': 0.9755760646207662, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 119, 'y': 207, 'w': 494, 'h': 494, 'left_eye': (141, 187), 'right_eye': (340, 200)}, 'img2': {'x': 81, 'y': 218, 'w': 374, 'h': 374, 'left_eye': (105, 140), 'right_eye': (252, 148)}}, 'time': 1.26}\n",
            "Result: {'verified': False, 'distance': 0.8120447463419336, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 119, 'y': 207, 'w': 494, 'h': 494, 'left_eye': (141, 187), 'right_eye': (340, 200)}, 'img2': {'x': 88, 'y': 248, 'w': 517, 'h': 517, 'left_eye': (139, 198), 'right_eye': (378, 199)}}, 'time': 1.58}\n",
            "Result: {'verified': False, 'distance': 1.1130840521117702, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 119, 'y': 207, 'w': 494, 'h': 494, 'left_eye': (141, 187), 'right_eye': (340, 200)}, 'img2': {'x': 0, 'y': 0, 'w': 441, 'h': 443, 'left_eye': None, 'right_eye': None}}, 'time': 1.29}\n",
            "Result: {'verified': False, 'distance': 0.8302632140508739, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 119, 'y': 207, 'w': 494, 'h': 494, 'left_eye': (141, 187), 'right_eye': (340, 200)}, 'img2': {'x': 140, 'y': 154, 'w': 426, 'h': 426, 'left_eye': (142, 160), 'right_eye': (283, 175)}}, 'time': 1.66}\n",
            "Result: {'verified': False, 'distance': 0.8104370198360851, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 119, 'y': 207, 'w': 494, 'h': 494, 'left_eye': (141, 187), 'right_eye': (340, 200)}, 'img2': {'x': 172, 'y': 203, 'w': 305, 'h': 305, 'left_eye': (87, 114), 'right_eye': (203, 118)}}, 'time': 1.46}\n",
            "Result: {'verified': False, 'distance': 1.0451017441919195, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 119, 'y': 207, 'w': 494, 'h': 494, 'left_eye': (141, 187), 'right_eye': (340, 200)}, 'img2': {'x': 263, 'y': 152, 'w': 153, 'h': 153, 'left_eye': None, 'right_eye': None}}, 'time': 1.42}\n",
            "Result: {'verified': False, 'distance': 0.9652968847088621, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 119, 'y': 207, 'w': 494, 'h': 494, 'left_eye': (141, 187), 'right_eye': (340, 200)}, 'img2': {'x': 0, 'y': 0, 'w': 749, 'h': 750, 'left_eye': None, 'right_eye': None}}, 'time': 2.27}\n",
            "Error: min() arg is an empty sequence\n",
            "Matched photos: None\n",
            "No matched image found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eO1WI_GnuieV",
        "outputId": "60b96d85-9b51-4872-ed40-cf175771b5b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Database images: ['/content/sa3dny_project/Face match child images/84.jpg', '/content/sa3dny_project/Face match child images/38.png', '/content/sa3dny_project/Face match child images/63.jpg', '/content/sa3dny_project/Face match child images/75.png', '/content/sa3dny_project/Face match child images/43.png', '/content/sa3dny_project/Face match child images/56.jpg', '/content/sa3dny_project/Face match child images/71.png', '/content/sa3dny_project/Face match child images/2.png', '/content/sa3dny_project/Face match child images/55.png', '/content/sa3dny_project/Face match child images/82.jpg', '/content/sa3dny_project/Face match child images/16.png', '/content/sa3dny_project/Face match child images/6.jpg', '/content/sa3dny_project/Face match child images/53.png', '/content/sa3dny_project/Face match child images/81.jpg', '/content/sa3dny_project/Face match child images/32.png', '/content/sa3dny_project/Face match child images/22.png', '/content/sa3dny_project/Face match child images/50.png', '/content/sa3dny_project/Face match child images/60.png', '/content/sa3dny_project/Face match child images/3.png', '/content/sa3dny_project/Face match child images/76.png', '/content/sa3dny_project/Face match child images/13.png', '/content/sa3dny_project/Face match child images/41.png', '/content/sa3dny_project/Face match child images/29.png', '/content/sa3dny_project/Face match child images/45.jpg', '/content/sa3dny_project/Face match child images/7.png', '/content/sa3dny_project/Face match child images/77.png', '/content/sa3dny_project/Face match child images/44.png', '/content/sa3dny_project/Face match child images/5.jpeg', '/content/sa3dny_project/Face match child images/31.png', '/content/sa3dny_project/Face match child images/69.png', '/content/sa3dny_project/Face match child images/27.jpg', '/content/sa3dny_project/Face match child images/40.png', '/content/sa3dny_project/Face match child images/20.png', '/content/sa3dny_project/Face match child images/39.png', '/content/sa3dny_project/Face match child images/57.jpg', '/content/sa3dny_project/Face match child images/42.png', '/content/sa3dny_project/Face match child images/35.png.jpg', '/content/sa3dny_project/Face match child images/67.jpg.jpg', '/content/sa3dny_project/Face match child images/52.png', '/content/sa3dny_project/Face match child images/8.png', '/content/sa3dny_project/Face match child images/17.jpg', '/content/sa3dny_project/Face match child images/61.png', '/content/sa3dny_project/Face match child images/30.png', '/content/sa3dny_project/Face match child images/78.png', '/content/sa3dny_project/Face match child images/58.jpg', '/content/sa3dny_project/Face match child images/62.png', '/content/sa3dny_project/Face match child images/66.jpg', '/content/sa3dny_project/Face match child images/14.png', '/content/sa3dny_project/Face match child images/18.png', '/content/sa3dny_project/Face match child images/68 (1).png', '/content/sa3dny_project/Face match child images/36.png', '/content/sa3dny_project/Face match child images/59.png', '/content/sa3dny_project/Face match child images/37.jpg', '/content/sa3dny_project/Face match child images/86.jpg', '/content/sa3dny_project/Face match child images/64.jpg', '/content/sa3dny_project/Face match child images/65.png', '/content/sa3dny_project/Face match child images/83.jpg', '/content/sa3dny_project/Face match child images/21.png', '/content/sa3dny_project/Face match child images/23.png', '/content/sa3dny_project/Face match child images/4.jpg', '/content/sa3dny_project/Face match child images/25.png', '/content/sa3dny_project/Face match child images/19.png', '/content/sa3dny_project/Face match child images/70.png', '/content/sa3dny_project/Face match child images/54.png', '/content/sa3dny_project/Face match child images/73.png', '/content/sa3dny_project/Face match child images/10.png', '/content/sa3dny_project/Face match child images/1.png', '/content/sa3dny_project/Face match child images/33.png', '/content/sa3dny_project/Face match child images/9.png', '/content/sa3dny_project/Face match child images/34.png', '/content/sa3dny_project/Face match child images/15.png', '/content/sa3dny_project/Face match child images/49.png', '/content/sa3dny_project/Face match child images/72.png', '/content/sa3dny_project/Face match child images/26.png', '/content/sa3dny_project/Face match child images/85.jpg', '/content/sa3dny_project/Face match child images/46.png', '/content/sa3dny_project/Face match child images/79.jpg', '/content/sa3dny_project/Face match child images/28.png', '/content/sa3dny_project/Face match child images/74.png', '/content/sa3dny_project/Face match child images/51.png', '/content/sa3dny_project/Face match child images/47.png', '/content/sa3dny_project/Face match child images/24.png', '/content/sa3dny_project/Face match child images/48.png']\n",
            "Error: min() arg is an empty sequence\n",
            "Matched photos: None\n"
          ]
        }
      ],
      "source": [
        "from deepface import DeepFace\n",
        "import os\n",
        "\n",
        "class FaceRecognizer:\n",
        "    def __init__(self, database_path):\n",
        "        self.database_path = database_path\n",
        "\n",
        "    def recognize_face(self, image_path):\n",
        "        try:\n",
        "            # Load the images in the database\n",
        "            database_images = [os.path.join(self.database_path, file) for file in os.listdir(self.database_path) if file.endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "            print(\"Database images:\", database_images)  # Add this line for debugging\n",
        "\n",
        "            if not database_images:\n",
        "                return \"No images found in the database\"\n",
        "\n",
        "            # Recognize faces in the image using FaceNet model\n",
        "            matched_photos = []\n",
        "            for db_photo in database_images:\n",
        "                result = DeepFace.verify(image_path, db_photo, model_name='Facenet', detector_backend='opencv', enforce_detection=False)\n",
        "                if result['verified']:\n",
        "                    matched_photos.append(os.path.basename(db_photo))\n",
        "\n",
        "            if matched_photos:\n",
        "                return matched_photos\n",
        "            else:\n",
        "                return \"No face recognized in the image\"\n",
        "\n",
        "        except Exception as e:\n",
        "            print(\"Error:\", str(e))\n",
        "            return None\n",
        "\n",
        "# Usage\n",
        "recognizer = FaceRecognizer(database_path='/content/sa3dny_project/Face match child images')\n",
        "image_path = '/content/sa3dny_project/13.png'\n",
        "result = recognizer.recognize_face(image_path)\n",
        "print(\"Matched photos:\", result)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}